# VR音乐驱动移动系统 (Music-Driven VR Locomotion)

这是一个创新的Unity VR课程项目，通过**实时音乐识别技术**来控制VR交互，实现**音乐与虚拟现实的结合**。

## 🎓 课程需求完成情况

本项目满足所有VR开发课程核心要求：

### ✅ Locomotion Systems (移动系统)
- **音乐驱动移动**：通过演奏不同音符控制移动方向和速度
- **Teleporting**：传送功能（待集成到XR Interaction Toolkit）
- **Snap Rotation**：快速旋转（待集成到XR Interaction Toolkit）
- **创新移动方式**：音乐控制移动 - 独特的metaphor实现

### ✅ Object Interaction (物体交互)
- **和弦触发抓取**：识别7和弦及以上复杂和弦触发物体抓取
- **Select/Grab/Throw**：基于音乐语义的交互系统

### ✅ Haptic Feedback (触觉反馈)
- **7和弦震动反馈**：检测到7和弦及以上时，头显震动反馈
- **交互增强**：通过震动增强沉浸感

### ✅ Sound Design (音效设计)
- **音乐即音效**：演奏本身作为交互音效系统
- **环境音频**：钢琴演奏声音作为背景音频
- **避免干扰**：不额外添加音效以保持演奏质量

## 项目概述

本项目实现了一个完整的**音乐驱动的VR交互系统**：

- 🎹 **实时钢琴识别**：使用深度学习模型实时识别钢琴演奏的音符
- 🎮 **音乐驱动移动**：将音符映射为VR移动动作（课程创新locomotion方式）
- 🎵 **和弦交互触发**：7和弦及以上触发物体抓取和震动反馈
- 🌐 **服务器架构**：Ubuntu GPU服务器部署模型，Unity客户端连接获取实时数据

## 技术架构

### 🏗️ 系统架构（当前实现）

```
[钢琴演奏] → [麦克风/音频接口] 
                  ↓
        [Ubuntu GPU服务器]
        [音频捕获 + 实时识别]
                  ↓
         [ONNX/PyTorch模型]
         [Zipformer转录]
                  ↓
        [音符+和弦+力度数据]
                  ↓
          [WebSocket API]
                  ↓
        ┌─────────┴─────────┐
        ↓                   ↓
   [Unity客户端]      [Quest头显]
   [ServerConnection]      ↓
        ↓           [VR交互场景]
        ↓                   ↓
        └───────┬───────────┘
                ↓
    ┌───────────┴───────────┬──────────────┐
    ↓                       ↓              ↓
[PianoMovementController] [GrabController] [HapticController]
   (音符驱动移动)          (7和弦抓取)    (7和弦震动)
```

**架构说明**：
- 🎹 **音频输入**：钢琴通过麦克风/音频接口直接连接到服务器
- 🖥️ **服务器处理**：Ubuntu GPU服务器负责音频捕获和实时识别
- 📡 **网络通信**：服务器通过WebSocket将识别结果发送给Unity
- 🥽 **Quest端**：仅接收数据和执行VR交互，无需音频捕获

### 核心功能模块

### 1. 服务器端音频处理（Ubuntu GPU）
- **音频捕获**：服务器直接连接麦克风/音频接口
- **实时识别**：Zipformer模型推理
- **数据输出**：音符、和弦、力度信息
- **API服务**：WebSocket低延迟通信

### 2. Unity客户端通信 (开发中)
- **ServerConnection.cs**：与Ubuntu GPU服务器通信
- **接收数据**：实时获取音符和和弦信息
- **事件分发**：将数据分发给各个控制器
- **低延迟协议**：WebSocket异步通信

### 3. 音乐驱动移动控制 (创新Locomotion)

#### PianoMovementController.cs
**音频驱动移动映射**（第一阶段：不考虑音乐语义）：

| 音符 | 移动动作 | 说明 |
|------|---------|------|
| C | 前进 | Forward |
| D | 右转 | Right |
| E | 后退 | Backward |
| F | 左转 | Left |
| G | 跳跃 | Jump |
| A | 向左移动 | Strafe Left |
| B | 向右移动 | Strafe Right |

**特色功能**：
- ✅ **音频驱动**：基于音频特征直接控制（第一阶段）
- ✅ **力度响应**：音符力度调整移动速度
- 🔄 **语义理解**（未来）：基于音乐情感和语义的智能移动

### 4. 和弦交互系统

#### GrabController.cs (开发中)
- **7和弦触发抓取**：检测7和弦（如Cmaj7, Dm7, G7等）
- **复杂和弦触发**：识别更复杂的和弦结构
- **物体选择和抓取**：满足课程Object Interaction要求

#### HapticController.cs (开发中)
- **震动反馈**：7和弦触发头显震动
- **触觉增强**：满足课程Haptic Feedback要求
- **强度可调**：根据和弦复杂度调整震动强度

## 快速开始

### 前置要求
- Unity 2021.3 或更高版本
- VR头显（Meta Quest, Vive, Index等）
- 钢琴或MIDI键盘（用于测试）
- Ubuntu GPU Server (For Tone Detection)

## 使用指南

### 音乐驱动移动控制

```
演奏 C → VR前进移动
演奏 D → VR向右旋转
演奏 E → VR后退移动
演奏 F → VR向左旋转
演奏 G → VR跳跃
演奏 A → VR左平移
演奏 B → VR右平移
```

### 和弦交互触发

```
演奏 Cmaj7 (C-E-G-B) → 触发物体抓取 + 震动反馈
演奏 Dm7 (D-F-A-C)  → 触发物体抓取 + 震动反馈
演奏 G7 (G-B-D-F)   → 触发物体抓取 + 震动反馈
```
## 许可证

本项目为课程作业项目，用于教育目的。

## 作者

Sheperd Hannigan  
Portfolio 2 - VR Locomotion Demo  
课程项目 - 音乐驱动VR交互系统

---

**项目说明**：
- 当前版本为开发阶段，使用模拟模式进行快速迭代
- Ubuntu GPU服务器部署中，实现低延迟实时识别
- 最终版本将满足所有课程要求并提供独特的音乐驱动交互体验
